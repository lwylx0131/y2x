1) sign(x)或者Sign(x)叫做符号函数，在数学和计算机运算中，其功能是取某个数的符号（正或负）：
当x>0，sign(x)=1;
当x=0，sign(x)=0;
当x<0， sign(x)=-1；

2) 向量A与向量B的内积公式：
A = (a1, a2)
B = (b1, b2)
A * B = ||A|| * ||B|| * cosθ = a1b1 + a2b2 = A(T)B
备注：A(T)表示A的转置，其中A和B都为列向量。

3) 超平面方程为W(T)X + b = 0，且向量W垂直于这个超平面，其中任意一点C到超平面距离d公式如下：
d = |W(T)C + b| / ||W||
备注：||W||表示向量W的长度。

4) 拉格朗日量：
L(X, α, β) = f(X) + ∑(i=1|k)αi * gi(X) + ∑(i=1|l)βi * hi(X)
其中KKT条件：
gi(X) <= 0, i=1,2,...,k
hi(X) = 0, i=1,2,...,l
αi >= 0, i=1,2,...,k
αi * gi(X) = 0, i=1,2,...,k
∂L(X, α, β) / ∂x(i) = 0, i=1,2,...,m

5) SVN问题中有m个数据{X(i), y(i)}，i = 1,2, …, m。对于实际问题重新定义X(i)到超平面h的距离为dist(X(i), h)，
又因为y(i)不是等于1就是-1，我们可以将上面 γ里面的绝对值去掉：
dist(x(i), h) = |W(T)X(i) + b| / ||W||
              = |y(i) * (W(T)X(i) + b)| / ||W||
              = y(i) * (W(T)X(i) + b) / ||W||

在m中，离超平面h最近点的距离，也就是间隔（margin）：
min{i=1,2,...,m} dist(X(i), h) = (1/||W||) * min{i=1,2,...,m} y(i) * (W(T)X(i) + b)
因为：min{i=1,2,...,m} y(i) * (W(T)X(i) + b) = 1
所以：min{i=1,2,...,m} dist(X(i), h) = (1/||W||) * min{i=1,2,...,m} y(i) * (W(T)X(i) + b) = 1/||W||

有了margin表达式后，只用最大化它：
max 1/||W|| = min ||W|| = min W(T)W = min (1/2)W(T)W

在SVM问题中，我们不但希望要最大化margin，还希望每个点都有分类正确，因为我们要解决下面优化问题：
min{b,w} (1/2)W(T)W
s.t. 
min{i=1,2,...,m} y(i) * (W(T)X(i) + b) = 1
优化变为：
min{b,w} (1/2)W(T)W
s.t. 
y(i) * (W(T)X(i) + b) >= 1, i=1,2,...,m

由限制条件可知，该问题是找一个超平面，线性分割所有点并使它们完全分类正确，这种超平面称为线性硬分隔支撑向量机(hard-margin SVM)。
因为目标函数是个关于 w 的二次函数，通常这类问题叫做二次规划 (quadratic programming, QP)。
